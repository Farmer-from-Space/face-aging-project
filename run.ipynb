{"cells":[{"cell_type":"markdown","metadata":{"id":"tlwOLgIhTBQ8"},"source":["# Use Model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E9aZlYl0MZom"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J2uubo7PsvxQ"},"outputs":[],"source":["%cd /face\n","!pip3 install -r requirements.txt\n","!python download_models.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rQKoh2xrw697"},"outputs":[],"source":["import os\n","from collections import OrderedDict\n","from options.test_options import TestOptions\n","from data.data_loader import CreateDataLoader\n","from models.models import create_model\n","import util.util as util\n","from util.visualizer import Visualizer\n","\n","opt = TestOptions().parse(save=False)\n","opt.display_id = 0 # do not launch visdom\n","opt.nThreads = 1   # test code only supports nThreads = 1\n","opt.batchSize = 1  # test code only supports batchSize = 1\n","opt.serial_batches = True  # no shuffle\n","opt.no_flip = True  # no flip\n","opt.in_the_wild = True # This triggers preprocessing of in the wild images in the dataloader\n","opt.traverse = True # This tells the model to traverse the latent space between anchor classes\n","opt.interp_step = 0.05 # this controls the number of images to interpolate between anchor classes\n","\n","data_loader = CreateDataLoader(opt)\n","dataset = data_loader.load_data()\n","visualizer = Visualizer(opt)"]},{"cell_type":"markdown","metadata":{"id":"jDnq2nS7T0QC"},"source":["# CoLab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FZsgYQSBl_9I"},"outputs":[],"source":["opt.name = 'males_model' # or 'femail_model'\n","model = create_model(opt)\n","model.eval()\n","\n","# upload your image (the code supports only a single image at a time)\n","from google.colab import files\n","uploaded = files.upload()\n","for filename in uploaded.keys():\n","  img_path = filename\n","  print('User uploaded file \"{name}\"'.format(name=filename))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Av4qUAeemAgQ"},"outputs":[],"source":["data = dataset.dataset.get_item_from_path(img_path)\n","visuals = model.inference(data)\n","\n","os.makedirs('results', exist_ok=True)\n","out_path = os.path.join('results', os.path.splitext(img_path)[0].replace(' ', '_') + '.mp4')\n","visualizer.make_video(visuals, out_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dDA0JPOfmCAG"},"outputs":[],"source":["# Result\n","# use_webm = False\n","\n","!pip3 install webm\n","webm_out_path = os.path.join('results', os.path.splitext(img_path)[0].replace(' ', '_') + '.webm')\n","# !webm -i $out_path $webm_out_path\n","use_webm = True\n","\n","from IPython.display import HTML\n","from base64 import b64encode\n","video_path = webm_out_path if use_webm else out_path\n","video_type = \"video/webm\" if use_webm else \"video/mp4\"\n","mp4 = open(video_path,'rb').read()\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","HTML(\"\"\"\n","<video width={0} controls>\n","      <source src=\"{1}\" type=\"{2}\">\n","</video>\n","\"\"\".format(opt.fineSize, data_url, video_type))"]},{"cell_type":"markdown","metadata":{"id":"_n9pJtLIT7zp"},"source":["# FLASK"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Dz3AeiTOs8c"},"outputs":[],"source":["!pip install flask-ngrok\n","!pip install pyngrok==4.1.1\n","!ngrok authtoken '<ngrok token password>'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DdPwCWosOub2"},"outputs":[],"source":["import os\n","from crypt import methods\n","from flask_ngrok import run_with_ngrok\n","import urllib.request\n","from flask import Flask, flash, request, redirect, url_for, render_template\n","from werkzeug.utils import secure_filename\n","import pandas as pd\n","\n","UPLOAD_FOLDER = 'static/uploads/'\n","\n","app = Flask(__name__)\n","run_with_ngrok(app) \n","\n","app.secret_key = \"secret key\"\n","app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n","app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6M1bMmluUhHb"},"outputs":[],"source":["ALLOWED_EXTENSIONS = set(['png', 'jpg', 'jpeg', 'gif'])\n","\n","def allowed_file(filename):\n","\treturn '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n","\n","@app.route('/', methods=['GET', 'POST'])\n","\n","def index():\n","    return render_template('index.html', title='face GAN')\n","\n","@app.route('/index', methods=['POST'])\n","\n","def aging():\n","    age = request.form['age']\n","    target_age = request.form['target_age']\n","    gender = request.form['gender']\n","    image = request.files['image']\n","    path = os.path.join(app.config[\"UPLOAD_FOLDER\"], image.filename)\n","    image.save(path)\n","    \n","    if gender == \"male\":\n","        input = pd.DataFrame({\n","        'age' : [int(age)],\n","        'target_age' :[int(target_age)]\n","        })\n","\n","        opt.name = 'males_model'\n","        model = create_model(opt)\n","        model.eval()\n","\n","    elif gender == \"female\":\n","        input = pd.DataFrame({\n","        'age' : [int(age)],\n","        'target_age' :[int(target_age)]\n","        })\n","\n","        opt.name = 'females_model'\n","        model = create_model(opt)\n","        model.eval()  \n","\n","    name = f'./static/uploads/{image.filename}'\n","    data = dataset.dataset.get_item_from_path(name)\n","    visuals = model.inference(data)\n","\n","    # Model running (images)\n","    os.makedirs(f'results/{image.filename}', exist_ok=True)\n","    out_pathi = f'./results/{image.filename}'   \n","\n","    visualizer.save_images_deploy(visuals, out_pathi)\n","    \n","    # Model running (video)\n","    os.makedirs('results', exist_ok=True)\n","    out_pathv = os.path.join('results', os.path.splitext(name)[0].replace(' ', '_') + '.webm')\n","    visualizer.make_video(visuals, out_pathv)\n","\n","    return render_template('output.html', filename=image.filename) #Output = ModelOutput)\n","\n","if __name__ == \"__main__\":\n","    app.run()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["@inproceedings{orel2020lifespan,\n","  title={Lifespan Age Transformation Synthesis},\n","  author={Or-El, Roy\n","          and Sengupta, Soumyadip\n","          and Fried, Ohad\n","          and Shechtman, Eli\n","          and Kemelmacher-Shlizerman, Ira},\n","  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},\n","  year={2020}\n","}"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"run.ipynb","private_outputs":true,"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.8.13 ('krc3')","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.13"},"vscode":{"interpreter":{"hash":"9ab68bc9b37578d62bcac5013120789b9661e00d8bcff4fda830d0f3b16c2dab"}}},"nbformat":4,"nbformat_minor":0}
